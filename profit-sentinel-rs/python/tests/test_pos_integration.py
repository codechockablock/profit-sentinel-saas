"""Integration tests: POS data → Adapter → Bridge → Rust Pipeline → Digest.

These tests verify the complete data flow from real POS exports
through the Python adapter layer, across the bridge converter, through the
Rust analysis pipeline, and back into typed Python Digest models.

Test tiers:
1. Fixture tests (always run) — Use pre-generated fixtures in tests/fixtures/
2. Real data tests (skip if not available) — Use actual CSV files

The fixture files are generated by scripts/generate_fixtures.py from real data:
- inventory_sample.csv: 1000 diverse rows (negatives, dead stock, low margin)
- inventory_full.csv: All 156K rows
"""

from __future__ import annotations

from datetime import date
from pathlib import Path

import pytest
from sentinel_agent.adapters.base import NormalizedInventory
from sentinel_agent.adapters.bridge import PipelineBridge
from sentinel_agent.engine import AnalysisResult, PipelineError, SentinelEngine
from sentinel_agent.models import Digest, IssueType

# Fixture paths
_FIXTURES = Path(__file__).parent / "fixtures"
_SAMPLE_FIXTURE = _FIXTURES / "inventory_sample.csv"
_FULL_FIXTURE = _FIXTURES / "inventory_full.csv"

# Real data paths
_REAL_CUSTOM1 = Path("/Users/joseph/Downloads/custom_1.csv")
_REAL_REPORTS = Path("/Users/joseph/Downloads/Reports")

# Check binary availability
_WORKSPACE = Path(__file__).resolve().parent.parent.parent
_BINARY = _WORKSPACE / "target" / "release" / "sentinel-server"
if not _BINARY.is_file():
    _BINARY = _WORKSPACE / "target" / "debug" / "sentinel-server"

_HAS_BINARY = _BINARY.is_file()


# ---------------------------------------------------------------------------
# Fixture-Based Tests (always run if fixtures exist)
# ---------------------------------------------------------------------------


@pytest.mark.skipif(
    not _SAMPLE_FIXTURE.exists(),
    reason="Sample fixture not generated (run scripts/generate_fixtures.py)",
)
class TestSampleFixture:
    """Tests using the 1000-row sample fixture."""

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_pipeline_runs_successfully(self):
        """The Rust pipeline should process the sample without errors."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=5)
        assert isinstance(digest, Digest)
        assert digest.summary.records_processed == 1000

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_finds_dead_stock(self):
        """Sample has 384 dead stock candidates — pipeline should detect them."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=10)

        dead_stock = [i for i in digest.issues if i.issue_type == IssueType.DEAD_STOCK]
        assert len(dead_stock) >= 1, "Should detect dead stock in sample data"
        assert dead_stock[0].dollar_impact > 0

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_finds_negative_inventory(self):
        """Sample has 105 negative inventory rows — pipeline should detect them."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=10)

        negative = [
            i for i in digest.issues if i.issue_type == IssueType.NEGATIVE_INVENTORY
        ]
        assert len(negative) >= 1, "Should detect negative inventory in sample data"

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_finds_margin_erosion(self):
        """Sample has 237 low margin items — pipeline should detect margin erosion."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=10)

        margin = [i for i in digest.issues if i.issue_type == IssueType.MARGIN_EROSION]
        assert len(margin) >= 1, "Should detect margin erosion in sample data"

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_total_dollar_impact_positive(self):
        """Total dollar impact should be positive and meaningful."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=10)
        assert (
            digest.summary.total_dollar_impact > 1000
        ), f"Expected significant dollar impact, got ${digest.summary.total_dollar_impact:.0f}"

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_pipeline_timing(self):
        """Pipeline should complete in under 5 seconds for 1000 rows."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=5)
        assert (
            digest.pipeline_ms < 5000
        ), f"Pipeline took {digest.pipeline_ms}ms — too slow for 1000 rows"

    @pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
    def test_issues_have_skus(self):
        """Every issue should reference at least one SKU."""
        engine = SentinelEngine()
        digest = engine.run(str(_SAMPLE_FIXTURE), top_k=5)
        for issue in digest.issues:
            assert len(issue.skus) > 0, f"Issue {issue.id} has no SKUs"
            for sku in issue.skus:
                assert sku.sku_id, "SKU should have an ID"


# ---------------------------------------------------------------------------
# Full Pipeline Integration (adapter → bridge → engine → digest)
# ---------------------------------------------------------------------------


@pytest.mark.skipif(
    not _REAL_CUSTOM1.exists(),
    reason="Real custom_1.csv not available",
)
@pytest.mark.skipif(not _HAS_BINARY, reason="sentinel-server binary not built")
class TestFullPipelineIntegration:
    """End-to-end: real CSV → adapter → bridge → Rust pipeline → Digest.

    Uses the pre-generated full fixture to avoid re-converting 156K rows
    in each test. The fixture was generated by scripts/generate_fixtures.py.

    NOTE: Full 156K-row tests require ~4 minutes due to O(n²) SKU lookup
    in the Rust context generator (known performance item for Phase 9).
    Run with: pytest -m slow --timeout=300
    """

    @pytest.mark.slow
    def test_adapter_to_bridge_to_pipeline(self):
        """Load full fixture through Rust pipeline, verify real issues."""
        if not _FULL_FIXTURE.exists():
            pytest.skip("Full fixture not generated")

        engine = SentinelEngine()
        digest = engine.run(str(_FULL_FIXTURE), top_k=10, timeout_seconds=300)

        assert digest.summary.records_processed >= 156000
        assert (
            digest.summary.total_issues >= 3
        ), "Should find at least 3 issue types in 156K real records"
        assert (
            digest.summary.total_dollar_impact > 10000
        ), f"Expected significant impact, got ${digest.summary.total_dollar_impact:.0f}"

        # Verify specific issue types are present
        issue_types = {i.issue_type for i in digest.issues}
        assert IssueType.DEAD_STOCK in issue_types, "Should find dead stock"
        assert (
            IssueType.NEGATIVE_INVENTORY in issue_types
        ), "Should find negative inventory"

    @pytest.mark.slow
    def test_run_from_adapter_method(self):
        """Test the convenience method SentinelEngine.run_from_adapter()."""
        from sentinel_agent.adapters.generic_pos import GenericPosAdapter

        adapter = GenericPosAdapter()
        result = adapter.ingest(_REAL_CUSTOM1, store_id="test-store")

        engine = SentinelEngine()
        analysis = engine.run_from_adapter(
            result.inventory_records,
            stores=["test-store"],
            top_k=10,
            timeout_seconds=300,
        )

        assert isinstance(analysis, AnalysisResult)
        assert analysis.records_converted >= 156000
        assert analysis.total_issues >= 3
        assert analysis.total_dollar_impact > 10000

        # Test enrichment (bidirectional bridge)
        for issue in analysis.digest.issues:
            for sku in issue.skus[:3]:
                original = analysis.enrich_sku(sku.sku_id, issue.store_id)
                # Most SKUs should be enrichable
                if original:
                    assert original.sku_id == sku.sku_id

    def test_enriched_detail_available(self):
        """Verify enrichment index provides adapter fields not in Rust output."""
        from sentinel_agent.adapters.generic_pos import GenericPosAdapter

        adapter = GenericPosAdapter()
        # Use only first 10K records to stay within timeout
        result = adapter.ingest(_REAL_CUSTOM1, store_id="test-store")
        subset = result.inventory_records[:10000]

        engine = SentinelEngine()
        analysis = engine.run_from_adapter(
            subset,
            stores=["test-store"],
            top_k=5,
            timeout_seconds=60,
        )

        # Find an enrichable SKU
        enriched = False
        for issue in analysis.digest.issues:
            for sku in issue.skus:
                original = analysis.enrich_sku(sku.sku_id, issue.store_id)
                if original and original.description:
                    # The Rust pipeline doesn't have description, vendor, bin —
                    # but the enrichment index does
                    assert original.description is not None
                    enriched = True
                    break
            if enriched:
                break

        assert enriched, "Should be able to enrich at least one SKU with adapter data"

    @pytest.mark.slow
    def test_pipeline_completes_full_dataset(self):
        """Pipeline should complete for 156K rows (takes ~4 min due to O(n²) SKU lookup)."""
        if not _FULL_FIXTURE.exists():
            pytest.skip("Full fixture not generated")

        engine = SentinelEngine()
        digest = engine.run(str(_FULL_FIXTURE), top_k=5, timeout_seconds=300)

        assert digest.summary.records_processed >= 156000
        assert digest.summary.total_issues >= 1


# ---------------------------------------------------------------------------
# Bridge Validation Tests
# ---------------------------------------------------------------------------


class TestBridgeValidation:
    """Verify bridge output matches what Rust expects."""

    def test_bridge_csv_parseable_by_rust(self):
        """Create a small bridge CSV and verify Rust can parse it."""
        if not _HAS_BINARY:
            pytest.skip("sentinel-server binary not built")

        records = [
            NormalizedInventory(
                sku_id="TEST-001",
                qty_on_hand=-10,
                unit_cost=25.00,
                retail_price=40.00,
                store_id="test-store",
                last_receipt_date=date(2025, 6, 1),
                on_order_qty=5,
                sales_ytd=600.0,
            ),
            NormalizedInventory(
                sku_id="TEST-002",
                qty_on_hand=100,
                unit_cost=10.00,
                retail_price=15.00,
                store_id="test-store",
                sales_ytd=0.0,
            ),
            NormalizedInventory(
                sku_id="TEST-003",
                qty_on_hand=50,
                unit_cost=80.00,
                retail_price=82.00,
                store_id="test-store",
                last_receipt_date=date(2025, 6, 15),
                sales_ytd=300.0,
            ),
        ]

        bridge = PipelineBridge(reference_date=date(2025, 7, 1), months_elapsed_ytd=6.0)
        csv_path = bridge.to_pipeline_csv(records)

        try:
            engine = SentinelEngine()
            digest = engine.run(str(csv_path), top_k=5)
            assert digest.summary.records_processed == 3
            # Should find at least one issue
            assert digest.summary.issues_detected >= 1
        finally:
            csv_path.unlink(missing_ok=True)

    def test_bridge_preserves_negative_inventory(self):
        """Negative qty must survive the bridge for NegativeInventory detection."""
        records = [
            NormalizedInventory(
                sku_id=f"NEG-{i}",
                qty_on_hand=-50 - i,
                unit_cost=30.0,
                retail_price=45.0,
                store_id="test-store",
            )
            for i in range(10)
        ]

        bridge = PipelineBridge()
        csv_path = bridge.to_pipeline_csv(records)

        try:
            import csv

            with open(csv_path) as f:
                reader = csv.DictReader(f)
                for row in reader:
                    assert (
                        float(row["qty_on_hand"]) < 0
                    ), f"Negative qty not preserved: {row['qty_on_hand']}"
        finally:
            csv_path.unlink(missing_ok=True)


# ---------------------------------------------------------------------------
# Error Handling Tests
# ---------------------------------------------------------------------------


class TestErrorHandling:
    def test_run_from_adapter_empty_records(self):
        """Should raise ValueError with empty records."""
        if not _HAS_BINARY:
            pytest.skip("sentinel-server binary not built")

        engine = SentinelEngine()
        with pytest.raises(ValueError, match="No inventory records"):
            engine.run_from_adapter([])
